{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Damage Location.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"D6H8u_1Ty2Ti","colab_type":"code","outputId":"b711799d-437b-48f9-8540-e74ab51f6b31","executionInfo":{"status":"ok","timestamp":1549516711447,"user_tz":-330,"elapsed":66965,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"IsRvd50Ey8r3","colab_type":"code","outputId":"a4037a43-b2d8-4215-830e-0681eda81e2a","executionInfo":{"status":"ok","timestamp":1549516766989,"user_tz":-330,"elapsed":1844,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import h5py\n","import sklearn\n","import keras\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","%matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"cEsPISVazHKe","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras.models import Sequential, load_model\n","from keras.layers import Dense, Convolution2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers import Activation, Dropout, Flatten\n","from keras.utils.np_utils import to_categorical\n","from keras import optimizers\n","from keras.regularizers import l2, l1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pP7KdBtjzK5z","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras import backend as K\n","K.set_image_dim_ordering('th')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oFf-dzc6zNlT","colab_type":"code","colab":{}},"cell_type":"code","source":["img_width, img_height = 256, 256\n","train_data_dir = '/content/drive/My Drive/Car Insurance/Damage Location/training'\n","validation_data_dir = '/content/drive/My Drive/Car Insurance/Damage Location/validation'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LtfVMQqbzXAz","colab_type":"code","colab":{}},"cell_type":"code","source":["def initialize_layers():\n","  model = Sequential()\n","    \n","  model.add(ZeroPadding2D((1,1),input_shape=(3, img_width, img_height)))\n","  model.add(Convolution2D(64, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(64, 3, 3, activation='relu'))\n","  model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(64, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(128, 3, 3, activation='relu'))\n","  model.add(MaxPooling2D((2,2), strides=(2,2)))\n","\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(64, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(256, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(256, 3, 3, activation='relu'))\n","  model.add(MaxPooling2D((2,2), strides=(2,2)))\n","  \n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(MaxPooling2D((2,2), strides=(2,2)))\n","  \n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(ZeroPadding2D((1,1)))\n","  model.add(Convolution2D(512, 3, 3, activation='relu'))\n","  model.add(MaxPooling2D((2,2), strides=(2,2)))\n","  \n","  return model\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"i4B4QGXezvvu","colab_type":"code","outputId":"46ef479a-4676-4f7c-c925-7ba84c5e2aed","executionInfo":{"status":"ok","timestamp":1549453406574,"user_tz":-330,"elapsed":1190830,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":4219}},"cell_type":"code","source":["train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40,\n","                                   width_shift_range=0.2, height_shift_range=0.2,\n","                                   shear_range=0.2, zoom_range=0.2,\n","                                   horizontal_flip=True, fill_mode='nearest')\n","\n","train_generator = train_datagen.flow_from_directory(train_data_dir,\n","                                                   target_size=(img_height, img_width),\n","                                                   batch_size=16, class_mode='categorical')\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n","                                                           target_size=(img_height, img_width),\n","                                                           batch_size=16, class_mode='categorical')\n","\n","model = initialize_layers()\n","model.add(Flatten())\n","model.add(Dense(256, activation = 'relu', W_regularizer=l2(0.01)))\n","model.add(Dropout(0.5)) \n","model.add(Dense(3, activation = 'sigmoid'))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = optimizers.SGD(lr=0.001, momentum=0.9),\n","              metrics=['accuracy'])\n","\n","model.fit_generator(train_generator, samples_per_epoch = 1036,\n","                    nb_epoch = 110, validation_data=validation_generator,\n","                    nb_val_samples = 171)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 1036 images belonging to 3 classes.\n","Found 171 images belonging to 3 classes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=64, epochs=110, validation_steps=171)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/110\n","64/64 [==============================] - 586s 9s/step - loss: 6.1597 - acc: 0.4014 - val_loss: 6.0878 - val_acc: 0.4277\n","Epoch 2/110\n","64/64 [==============================] - 51s 799ms/step - loss: 6.0276 - acc: 0.4082 - val_loss: 5.9593 - val_acc: 0.4258\n","Epoch 3/110\n","64/64 [==============================] - 49s 768ms/step - loss: 5.8986 - acc: 0.4180 - val_loss: 5.8336 - val_acc: 0.4273\n","Epoch 4/110\n","64/64 [==============================] - 49s 766ms/step - loss: 5.7825 - acc: 0.4059 - val_loss: 5.7182 - val_acc: 0.4251\n","Epoch 5/110\n","64/64 [==============================] - 49s 762ms/step - loss: 5.6611 - acc: 0.4121 - val_loss: 5.5954 - val_acc: 0.4280\n","Epoch 6/110\n","64/64 [==============================] - 49s 761ms/step - loss: 5.5462 - acc: 0.4063 - val_loss: 5.4824 - val_acc: 0.4270\n","Epoch 7/110\n","64/64 [==============================] - 49s 762ms/step - loss: 5.4297 - acc: 0.4225 - val_loss: 5.3693 - val_acc: 0.4269\n","Epoch 8/110\n","64/64 [==============================] - 49s 759ms/step - loss: 5.3224 - acc: 0.4115 - val_loss: 5.2610 - val_acc: 0.4281\n","Epoch 9/110\n","64/64 [==============================] - 49s 761ms/step - loss: 5.2156 - acc: 0.4144 - val_loss: 5.1546 - val_acc: 0.4254\n","Epoch 10/110\n","64/64 [==============================] - 49s 761ms/step - loss: 5.1086 - acc: 0.4111 - val_loss: 5.0514 - val_acc: 0.4288\n","Epoch 11/110\n","64/64 [==============================] - 49s 762ms/step - loss: 5.0091 - acc: 0.4079 - val_loss: 4.9508 - val_acc: 0.4258\n","Epoch 12/110\n","64/64 [==============================] - 49s 759ms/step - loss: 4.9069 - acc: 0.4040 - val_loss: 4.8530 - val_acc: 0.4254\n","Epoch 13/110\n","64/64 [==============================] - 49s 759ms/step - loss: 4.8080 - acc: 0.4189 - val_loss: 4.7556 - val_acc: 0.4285\n","Epoch 14/110\n","64/64 [==============================] - 49s 761ms/step - loss: 4.7160 - acc: 0.4079 - val_loss: 4.6614 - val_acc: 0.4284\n","Epoch 15/110\n","64/64 [==============================] - 49s 760ms/step - loss: 4.6285 - acc: 0.4037 - val_loss: 4.5717 - val_acc: 0.4266\n","Epoch 16/110\n","64/64 [==============================] - 49s 762ms/step - loss: 4.5309 - acc: 0.4229 - val_loss: 4.4825 - val_acc: 0.4269\n","Epoch 17/110\n","64/64 [==============================] - 49s 762ms/step - loss: 4.4498 - acc: 0.4040 - val_loss: 4.3974 - val_acc: 0.4255\n","Epoch 18/110\n","64/64 [==============================] - 49s 760ms/step - loss: 4.3617 - acc: 0.4118 - val_loss: 4.3111 - val_acc: 0.4273\n","Epoch 19/110\n","64/64 [==============================] - 49s 759ms/step - loss: 4.2795 - acc: 0.4037 - val_loss: 4.2293 - val_acc: 0.4288\n","Epoch 20/110\n","64/64 [==============================] - 49s 763ms/step - loss: 4.1970 - acc: 0.4245 - val_loss: 4.1501 - val_acc: 0.4239\n","Epoch 21/110\n","64/64 [==============================] - 49s 762ms/step - loss: 4.1206 - acc: 0.3981 - val_loss: 4.0689 - val_acc: 0.4281\n","Epoch 22/110\n","64/64 [==============================] - 49s 760ms/step - loss: 4.0409 - acc: 0.4186 - val_loss: 3.9934 - val_acc: 0.4266\n","Epoch 23/110\n","64/64 [==============================] - 49s 763ms/step - loss: 3.9683 - acc: 0.4150 - val_loss: 3.9189 - val_acc: 0.4277\n","Epoch 24/110\n","64/64 [==============================] - 49s 761ms/step - loss: 3.8955 - acc: 0.3978 - val_loss: 3.8460 - val_acc: 0.4266\n","Epoch 25/110\n","64/64 [==============================] - 49s 762ms/step - loss: 3.8185 - acc: 0.4209 - val_loss: 3.7729 - val_acc: 0.4277\n","Epoch 26/110\n","64/64 [==============================] - 49s 760ms/step - loss: 3.7523 - acc: 0.4114 - val_loss: 3.7037 - val_acc: 0.4243\n","Epoch 27/110\n","64/64 [==============================] - 49s 761ms/step - loss: 3.6834 - acc: 0.4098 - val_loss: 3.6347 - val_acc: 0.4269\n","Epoch 28/110\n","64/64 [==============================] - 49s 760ms/step - loss: 3.6148 - acc: 0.4180 - val_loss: 3.5671 - val_acc: 0.4296\n","Epoch 29/110\n","64/64 [==============================] - 49s 762ms/step - loss: 3.5517 - acc: 0.4088 - val_loss: 3.5030 - val_acc: 0.4254\n","Epoch 30/110\n","64/64 [==============================] - 49s 758ms/step - loss: 3.4923 - acc: 0.3981 - val_loss: 3.4383 - val_acc: 0.4281\n","Epoch 31/110\n","64/64 [==============================] - 49s 765ms/step - loss: 3.4255 - acc: 0.4238 - val_loss: 3.3739 - val_acc: 0.4273\n","Epoch 32/110\n","64/64 [==============================] - 50s 783ms/step - loss: 3.3685 - acc: 0.4079 - val_loss: 3.3164 - val_acc: 0.4251\n","Epoch 33/110\n","64/64 [==============================] - 49s 764ms/step - loss: 3.3027 - acc: 0.4150 - val_loss: 3.2521 - val_acc: 0.4273\n","Epoch 34/110\n","64/64 [==============================] - 49s 760ms/step - loss: 3.2539 - acc: 0.4183 - val_loss: 3.2037 - val_acc: 0.4265\n","Epoch 35/110\n","64/64 [==============================] - 49s 758ms/step - loss: 3.1940 - acc: 0.4098 - val_loss: 3.1349 - val_acc: 0.4277\n","Epoch 36/110\n","64/64 [==============================] - 49s 761ms/step - loss: 3.1412 - acc: 0.4160 - val_loss: 3.0819 - val_acc: 0.4325\n","Epoch 37/110\n","64/64 [==============================] - 49s 758ms/step - loss: 3.0870 - acc: 0.4121 - val_loss: 3.0271 - val_acc: 0.4383\n","Epoch 38/110\n","64/64 [==============================] - 49s 761ms/step - loss: 3.0338 - acc: 0.4199 - val_loss: 2.9741 - val_acc: 0.4438\n","Epoch 39/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.9750 - acc: 0.4359 - val_loss: 2.9373 - val_acc: 0.4906\n","Epoch 40/110\n","64/64 [==============================] - 49s 761ms/step - loss: 2.9400 - acc: 0.4238 - val_loss: 2.8794 - val_acc: 0.4705\n","Epoch 41/110\n","64/64 [==============================] - 49s 763ms/step - loss: 2.8697 - acc: 0.4437 - val_loss: 2.8219 - val_acc: 0.5030\n","Epoch 42/110\n","64/64 [==============================] - 49s 764ms/step - loss: 2.8392 - acc: 0.4274 - val_loss: 2.7826 - val_acc: 0.4957\n","Epoch 43/110\n","64/64 [==============================] - 49s 760ms/step - loss: 2.7913 - acc: 0.4508 - val_loss: 2.7454 - val_acc: 0.4955\n","Epoch 44/110\n","64/64 [==============================] - 49s 759ms/step - loss: 2.7477 - acc: 0.4274 - val_loss: 2.6828 - val_acc: 0.4932\n","Epoch 45/110\n","64/64 [==============================] - 49s 760ms/step - loss: 2.6994 - acc: 0.4404 - val_loss: 2.6365 - val_acc: 0.4739\n","Epoch 46/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.6599 - acc: 0.4284 - val_loss: 2.5974 - val_acc: 0.4925\n","Epoch 47/110\n","64/64 [==============================] - 49s 764ms/step - loss: 2.6145 - acc: 0.4326 - val_loss: 2.5474 - val_acc: 0.4976\n","Epoch 48/110\n","64/64 [==============================] - 49s 758ms/step - loss: 2.5840 - acc: 0.4219 - val_loss: 2.5169 - val_acc: 0.4962\n","Epoch 49/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.5201 - acc: 0.4564 - val_loss: 2.4644 - val_acc: 0.4859\n","Epoch 50/110\n","64/64 [==============================] - 49s 759ms/step - loss: 2.4846 - acc: 0.4642 - val_loss: 2.4455 - val_acc: 0.4748\n","Epoch 51/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.4653 - acc: 0.4427 - val_loss: 2.4050 - val_acc: 0.4810\n","Epoch 52/110\n","64/64 [==============================] - 49s 763ms/step - loss: 2.4303 - acc: 0.4284 - val_loss: 2.3824 - val_acc: 0.5015\n","Epoch 53/110\n","64/64 [==============================] - 49s 763ms/step - loss: 2.3855 - acc: 0.4486 - val_loss: 2.3298 - val_acc: 0.4908\n","Epoch 54/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.3698 - acc: 0.4427 - val_loss: 2.2929 - val_acc: 0.5026\n","Epoch 55/110\n","64/64 [==============================] - 49s 761ms/step - loss: 2.3103 - acc: 0.4697 - val_loss: 2.2570 - val_acc: 0.4977\n","Epoch 56/110\n","64/64 [==============================] - 49s 761ms/step - loss: 2.2950 - acc: 0.4183 - val_loss: 2.2283 - val_acc: 0.5100\n","Epoch 57/110\n","64/64 [==============================] - 49s 761ms/step - loss: 2.2542 - acc: 0.4557 - val_loss: 2.1821 - val_acc: 0.4729\n","Epoch 58/110\n","64/64 [==============================] - 49s 761ms/step - loss: 2.2189 - acc: 0.4779 - val_loss: 2.1710 - val_acc: 0.4641\n","Epoch 59/110\n","64/64 [==============================] - 50s 778ms/step - loss: 2.1963 - acc: 0.4541 - val_loss: 2.1386 - val_acc: 0.4793\n","Epoch 60/110\n","64/64 [==============================] - 50s 775ms/step - loss: 2.1569 - acc: 0.4570 - val_loss: 2.1042 - val_acc: 0.4859\n","Epoch 61/110\n","64/64 [==============================] - 49s 760ms/step - loss: 2.1477 - acc: 0.4489 - val_loss: 2.0833 - val_acc: 0.4974\n","Epoch 62/110\n","64/64 [==============================] - 49s 762ms/step - loss: 2.1081 - acc: 0.4635 - val_loss: 2.0631 - val_acc: 0.4976\n","Epoch 63/110\n","64/64 [==============================] - 49s 760ms/step - loss: 2.0817 - acc: 0.4534 - val_loss: 2.0270 - val_acc: 0.4861\n","Epoch 64/110\n","64/64 [==============================] - 49s 763ms/step - loss: 2.0453 - acc: 0.4626 - val_loss: 1.9909 - val_acc: 0.5152\n","Epoch 65/110\n","64/64 [==============================] - 49s 759ms/step - loss: 2.0367 - acc: 0.4466 - val_loss: 1.9851 - val_acc: 0.4849\n","Epoch 66/110\n","64/64 [==============================] - 49s 764ms/step - loss: 2.0027 - acc: 0.4600 - val_loss: 1.9397 - val_acc: 0.4974\n","Epoch 67/110\n","64/64 [==============================] - 49s 765ms/step - loss: 1.9739 - acc: 0.4622 - val_loss: 1.9298 - val_acc: 0.5276\n","Epoch 68/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.9497 - acc: 0.4714 - val_loss: 1.9193 - val_acc: 0.4906\n","Epoch 69/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.9174 - acc: 0.4795 - val_loss: 1.8655 - val_acc: 0.5389\n","Epoch 70/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.9077 - acc: 0.4544 - val_loss: 1.8568 - val_acc: 0.5151\n","Epoch 71/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.8844 - acc: 0.4616 - val_loss: 1.8324 - val_acc: 0.5130\n","Epoch 72/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.8595 - acc: 0.4610 - val_loss: 1.8046 - val_acc: 0.5090\n","Epoch 73/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.8416 - acc: 0.4642 - val_loss: 1.7898 - val_acc: 0.4987\n","Epoch 74/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.8357 - acc: 0.4619 - val_loss: 1.7814 - val_acc: 0.5260\n","Epoch 75/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.8056 - acc: 0.4675 - val_loss: 1.7591 - val_acc: 0.4983\n","Epoch 76/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.7745 - acc: 0.4710 - val_loss: 1.7289 - val_acc: 0.5139\n","Epoch 77/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.7633 - acc: 0.4824 - val_loss: 1.7163 - val_acc: 0.5452\n","Epoch 78/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.7336 - acc: 0.4847 - val_loss: 1.6899 - val_acc: 0.5385\n","Epoch 79/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.7213 - acc: 0.4749 - val_loss: 1.6707 - val_acc: 0.5369\n","Epoch 80/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.7009 - acc: 0.4697 - val_loss: 1.6569 - val_acc: 0.5073\n","Epoch 81/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.6944 - acc: 0.4626 - val_loss: 1.6415 - val_acc: 0.5147\n","Epoch 82/110\n","64/64 [==============================] - 49s 766ms/step - loss: 1.6711 - acc: 0.4658 - val_loss: 1.6163 - val_acc: 0.5629\n","Epoch 83/110\n","64/64 [==============================] - 48s 758ms/step - loss: 1.6608 - acc: 0.4801 - val_loss: 1.6310 - val_acc: 0.4898\n","Epoch 84/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.6444 - acc: 0.4648 - val_loss: 1.6005 - val_acc: 0.4983\n","Epoch 85/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.6306 - acc: 0.4528 - val_loss: 1.5773 - val_acc: 0.5324\n","Epoch 86/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.6145 - acc: 0.4658 - val_loss: 1.5612 - val_acc: 0.5427\n","Epoch 87/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.5981 - acc: 0.4658 - val_loss: 1.5450 - val_acc: 0.4966\n","Epoch 88/110\n","64/64 [==============================] - 50s 782ms/step - loss: 1.5786 - acc: 0.4694 - val_loss: 1.5351 - val_acc: 0.5335\n","Epoch 89/110\n","64/64 [==============================] - 49s 772ms/step - loss: 1.5942 - acc: 0.4538 - val_loss: 1.5303 - val_acc: 0.4795\n","Epoch 90/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.5434 - acc: 0.4818 - val_loss: 1.5126 - val_acc: 0.5463\n","Epoch 91/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.5377 - acc: 0.4603 - val_loss: 1.4955 - val_acc: 0.5678\n","Epoch 92/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.5265 - acc: 0.4775 - val_loss: 1.4984 - val_acc: 0.4695\n","Epoch 93/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.5331 - acc: 0.4596 - val_loss: 1.4752 - val_acc: 0.5475\n","Epoch 94/110\n","64/64 [==============================] - 49s 759ms/step - loss: 1.5116 - acc: 0.4681 - val_loss: 1.4483 - val_acc: 0.5286\n","Epoch 95/110\n","64/64 [==============================] - 49s 765ms/step - loss: 1.4925 - acc: 0.4766 - val_loss: 1.4506 - val_acc: 0.5314\n","Epoch 96/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.4858 - acc: 0.4782 - val_loss: 1.4235 - val_acc: 0.5143\n","Epoch 97/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.4598 - acc: 0.4814 - val_loss: 1.4110 - val_acc: 0.5130\n","Epoch 98/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.4778 - acc: 0.4577 - val_loss: 1.4137 - val_acc: 0.5294\n","Epoch 99/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.4495 - acc: 0.4593 - val_loss: 1.3875 - val_acc: 0.5471\n","Epoch 100/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.4344 - acc: 0.4798 - val_loss: 1.3897 - val_acc: 0.5596\n","Epoch 101/110\n","64/64 [==============================] - 49s 761ms/step - loss: 1.4254 - acc: 0.4639 - val_loss: 1.3836 - val_acc: 0.5297\n","Epoch 102/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.4103 - acc: 0.4857 - val_loss: 1.3693 - val_acc: 0.5393\n","Epoch 103/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.3944 - acc: 0.4990 - val_loss: 1.3827 - val_acc: 0.5200\n","Epoch 104/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.4197 - acc: 0.4440 - val_loss: 1.3463 - val_acc: 0.5547\n","Epoch 105/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.3757 - acc: 0.4801 - val_loss: 1.3292 - val_acc: 0.5132\n","Epoch 106/110\n","64/64 [==============================] - 49s 760ms/step - loss: 1.3854 - acc: 0.4704 - val_loss: 1.3285 - val_acc: 0.5393\n","Epoch 107/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.3571 - acc: 0.4749 - val_loss: 1.3086 - val_acc: 0.5377\n","Epoch 108/110\n","64/64 [==============================] - 49s 762ms/step - loss: 1.3644 - acc: 0.4828 - val_loss: 1.3156 - val_acc: 0.4961\n","Epoch 109/110\n","64/64 [==============================] - 49s 763ms/step - loss: 1.3522 - acc: 0.4613 - val_loss: 1.3052 - val_acc: 0.5132\n","Epoch 110/110\n","64/64 [==============================] - 49s 764ms/step - loss: 1.3407 - acc: 0.4955 - val_loss: 1.3094 - val_acc: 0.4861\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f563acdc400>"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"9oUCQNT1BDHp","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, History\n","from keras.utils.np_utils import to_categorical"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SBICsc4fDaAW","colab_type":"code","colab":{}},"cell_type":"code","source":["def bottleneck_features():\n","  \n","  model = initialize_layers()\n","  \n","  datagen = ImageDataGenerator(rescale=1./255) \n","  \n","  generator_train = datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height),\n","                                                batch_size=16, class_mode=None, shuffle=False)\n","  nb_train_samples = len(generator_train.filenames) \n","  train_size = int(math.ceil(nb_train_samples / 16)) \n","  bottleneck_features_train = model.predict_generator(generator_train, train_size)\n","  np.save(open('/content/drive/My Drive/Car Insurance/Damage Location/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n","  \n","  \n","  generator_validation = datagen.flow_from_directory(validation_data_dir, target_size=(img_width, img_height),\n","                                                     batch_size=16, class_mode=None, shuffle=False)\n","  nb_validation_samples = len(generator_validation.filenames)\n","  vaidation_size = int(math.ceil(nb_validation_samples / 16)) \n","  bottleneck_features_validation = model.predict_generator(generator_validation, vaidation_size)\n","  np.save(open('/content/drive/My Drive/Car Insurance/Damage Location/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"O0yGNiPgVg8y","colab_type":"code","outputId":"3da430dc-8071-4fdb-dd77-656d7674d027","executionInfo":{"status":"ok","timestamp":1549470251996,"user_tz":-330,"elapsed":1343,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["os.getcwd()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"HIVNkdy5VZAL","colab_type":"code","colab":{}},"cell_type":"code","source":["path = '/content/drive/My Drive/Car Insurance/Damage Location'\n","os.chdir(path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TX58-gS6VnW7","colab_type":"code","outputId":"d157705c-386f-408b-851e-df0f22663edd","executionInfo":{"status":"ok","timestamp":1549470264140,"user_tz":-330,"elapsed":1423,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["os.getcwd()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Car Insurance/Damage Location'"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"KX87IFJTVL1V","colab_type":"code","colab":{}},"cell_type":"code","source":["train_samples = [len(os.listdir(train_data_dir+'/'+i)) for i in sorted(os.listdir(train_data_dir))]\n","validation_samples = [len(os.listdir(validation_data_dir+'/'+i)) for i in sorted(os.listdir(validation_data_dir))]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mUwQ5_IDV2jK","colab_type":"code","outputId":"10217d81-f1ee-4a8d-c574-d7dd2035bcfa","executionInfo":{"status":"ok","timestamp":1549518085482,"user_tz":-330,"elapsed":1059,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["print(train_samples)\n","print(validation_samples)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[426, 322, 288]\n","[73, 50, 48]\n"],"name":"stdout"}]},{"metadata":{"id":"7k-yiS1bamnj","colab_type":"code","colab":{}},"cell_type":"code","source":["top_model_weights_path = '/content/drive/My Drive/Car Insurance/Damage Location/top_model_weights.h5'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bWP1yUkXI6GE","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_categorical_model():\n","  train_data = np.load(open('/content/drive/My Drive/Car Insurance/Damage Location/bottleneck_features_train.npy', 'rb'))\n","  train_labels = np.array([0] * train_samples[0] + \n","                          [1] * train_samples[1] + \n","                          [2] * train_samples[2])\n","  train_labels = to_categorical(train_labels)\n","  \n","  validation_data = np.load(open('/content/drive/My Drive/Car Insurance/Damage Location/bottleneck_features_validation.npy', 'rb'))\n","  \n","  validation_labels = np.array([0] * validation_samples[0] + \n","                               [1] * validation_samples[1] +\n","                               [2] * validation_samples[2])\n","  validation_labels = to_categorical(validation_labels)\n","  \n","  model = Sequential()\n","  model.add(Flatten(input_shape=train_data.shape[1:])) # 512, 4, 4\n","  model.add(Dense(256, activation = 'relu', W_regularizer=l2(0.01)))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(3, activation = 'softmax'))\n","  \n","  model.compile(optimizers.SGD(lr=0.001, momentum=0.9),\n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","  \n","  #checkpoint = ModelCheckpoint(top_model_weights_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n","  \n","  model.fit(train_data, train_labels,\n","            nb_epoch = 50, batch_size=16,\n","           validation_data=(validation_data, validation_labels))\n","  \n","  model.save_weights('/content/drive/My Drive/Car Insurance/Damage Location/top_model_weights.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UHT67kt7coop","colab_type":"code","colab":{}},"cell_type":"code","source":["fine_tuned_model_path = '/content/drive/My Drive/Car Insurance/Damage Location/ft_model.h5'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RDR2b4jda9wd","colab_type":"code","colab":{}},"cell_type":"code","source":["def model_tuning():\n","  model = initialize_layers()\n","  top_model = Sequential()\n","  top_model.add(Flatten(input_shape=model.output_shape[1:]))\n","  top_model.add(Dense(256, activation='relu'))\n","  #top_model.add(Dense(256, activation='relu', W_regularizer=l2(0.01)))\n","  top_model.add(Dropout(0.5))\n","  top_model.add(Dense(3, activation='softmax'))\n","\n","  top_model.load_weights(top_model_weights_path) \n","  \n","  model.add(top_model)\n","  \n","  for layer in model.layers[:25]:\n","        layer.trainable=False\n","      \n","  model.compile(loss='categorical_crossentropy',\n","                 optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), # reduced learning rate by 1/10\n","                  metrics=['accuracy'])\n","  \n","  datagen = ImageDataGenerator(rescale=1./255,\n","                                       rotation_range=40,\n","                                       width_shift_range=0.2,\n","                                       height_shift_range=0.2,\n","                                       shear_range=0.2,\n","                                       zoom_range=0.2,\n","                                       horizontal_flip=True,\n","                                       fill_mode='nearest')\n","  \n","  train_generator= datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width),\n","                                                     batch_size=8, class_mode='categorical')\n","\n","  validation_generator = datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width),\n","                                                           batch_size=8, class_mode='categorical')\n","    \n","    \n","  checkpoint = ModelCheckpoint(fine_tuned_model_path, monitor='val_acc', \n","                                 verbose=1, save_best_only=True, \n","                                 save_weights_only=False, mode='auto')\n","  \n","  fit = model.fit_generator(train_generator, samples_per_epoch = 1036,\n","                        nb_epoch = 100, validation_data=validation_generator,\n","                        nb_val_samples = 171, verbose = 1,\n","                        callbacks=[checkpoint])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M71HAj5beDPb","colab_type":"code","outputId":"09dc7efe-4f09-4d62-ea2e-298c38e9f6e5","executionInfo":{"status":"ok","timestamp":1549517836878,"user_tz":-330,"elapsed":80544,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"cell_type":"code","source":["bottleneck_features()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["Found 1036 images belonging to 3 classes.\n","Found 171 images belonging to 3 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"tbkKds57elpa","colab_type":"code","outputId":"9a23404f-65ae-4a7f-d328-29af45ff67b9","executionInfo":{"status":"ok","timestamp":1549518549998,"user_tz":-330,"elapsed":42034,"user":{"displayName":"Koushik Parepalli","photoUrl":"https://lh6.googleusercontent.com/-IvaigHAqErY/AAAAAAAAAAI/AAAAAAAACTQ/bF1chiD6PxY/s64/photo.jpg","userId":"09812122192418750149"}},"colab":{"base_uri":"https://localhost:8080/","height":1788}},"cell_type":"code","source":["train_categorical_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 1036 samples, validate on 171 samples\n","Epoch 1/50\n","1036/1036 [==============================] - 2s 2ms/step - loss: 6.1242 - acc: 0.3977 - val_loss: 6.0559 - val_acc: 0.4269\n","Epoch 2/50\n","1036/1036 [==============================] - 1s 731us/step - loss: 5.9923 - acc: 0.4112 - val_loss: 5.9232 - val_acc: 0.4269\n","Epoch 3/50\n","1036/1036 [==============================] - 1s 785us/step - loss: 5.8631 - acc: 0.4112 - val_loss: 5.7961 - val_acc: 0.4269\n","Epoch 4/50\n","1036/1036 [==============================] - 1s 769us/step - loss: 5.7391 - acc: 0.4112 - val_loss: 5.6737 - val_acc: 0.4269\n","Epoch 5/50\n","1036/1036 [==============================] - 1s 758us/step - loss: 5.6193 - acc: 0.4112 - val_loss: 5.5548 - val_acc: 0.4269\n","Epoch 6/50\n","1036/1036 [==============================] - 1s 763us/step - loss: 5.5023 - acc: 0.4112 - val_loss: 5.4395 - val_acc: 0.4269\n","Epoch 7/50\n","1036/1036 [==============================] - 1s 794us/step - loss: 5.3888 - acc: 0.4112 - val_loss: 5.3276 - val_acc: 0.4269\n","Epoch 8/50\n","1036/1036 [==============================] - 1s 814us/step - loss: 5.2777 - acc: 0.4112 - val_loss: 5.2182 - val_acc: 0.4269\n","Epoch 9/50\n","1036/1036 [==============================] - 1s 758us/step - loss: 5.1698 - acc: 0.4112 - val_loss: 5.1115 - val_acc: 0.4269\n","Epoch 10/50\n","1036/1036 [==============================] - 1s 780us/step - loss: 5.0647 - acc: 0.4112 - val_loss: 5.0078 - val_acc: 0.4269\n","Epoch 11/50\n","1036/1036 [==============================] - 1s 777us/step - loss: 4.9622 - acc: 0.4112 - val_loss: 4.9069 - val_acc: 0.4269\n","Epoch 12/50\n","1036/1036 [==============================] - 1s 760us/step - loss: 4.8636 - acc: 0.4112 - val_loss: 4.8085 - val_acc: 0.4269\n","Epoch 13/50\n","1036/1036 [==============================] - 1s 767us/step - loss: 4.7657 - acc: 0.4112 - val_loss: 4.7127 - val_acc: 0.4269\n","Epoch 14/50\n","1036/1036 [==============================] - 1s 776us/step - loss: 4.6711 - acc: 0.4112 - val_loss: 4.6191 - val_acc: 0.4269\n","Epoch 15/50\n","1036/1036 [==============================] - 1s 791us/step - loss: 4.5791 - acc: 0.4112 - val_loss: 4.5282 - val_acc: 0.4269\n","Epoch 16/50\n","1036/1036 [==============================] - 1s 785us/step - loss: 4.4886 - acc: 0.4112 - val_loss: 4.4397 - val_acc: 0.4269\n","Epoch 17/50\n","1036/1036 [==============================] - 1s 753us/step - loss: 4.4010 - acc: 0.4112 - val_loss: 4.3533 - val_acc: 0.4269\n","Epoch 18/50\n","1036/1036 [==============================] - 1s 768us/step - loss: 4.3166 - acc: 0.4112 - val_loss: 4.2689 - val_acc: 0.4269\n","Epoch 19/50\n","1036/1036 [==============================] - 1s 767us/step - loss: 4.2331 - acc: 0.4112 - val_loss: 4.1870 - val_acc: 0.4269\n","Epoch 20/50\n","1036/1036 [==============================] - 1s 763us/step - loss: 4.1521 - acc: 0.4112 - val_loss: 4.1071 - val_acc: 0.4269\n","Epoch 21/50\n","1036/1036 [==============================] - 1s 762us/step - loss: 4.0731 - acc: 0.4112 - val_loss: 4.0294 - val_acc: 0.4269\n","Epoch 22/50\n","1036/1036 [==============================] - 1s 741us/step - loss: 3.9961 - acc: 0.4112 - val_loss: 3.9536 - val_acc: 0.4269\n","Epoch 23/50\n","1036/1036 [==============================] - 1s 776us/step - loss: 3.9215 - acc: 0.4112 - val_loss: 3.8795 - val_acc: 0.4269\n","Epoch 24/50\n","1036/1036 [==============================] - 1s 767us/step - loss: 3.8487 - acc: 0.4112 - val_loss: 3.8076 - val_acc: 0.4269\n","Epoch 25/50\n","1036/1036 [==============================] - 1s 754us/step - loss: 3.7775 - acc: 0.4112 - val_loss: 3.7376 - val_acc: 0.4269\n","Epoch 26/50\n","1036/1036 [==============================] - 1s 758us/step - loss: 3.7076 - acc: 0.4112 - val_loss: 3.6691 - val_acc: 0.4269\n","Epoch 27/50\n","1036/1036 [==============================] - 1s 772us/step - loss: 3.6412 - acc: 0.4112 - val_loss: 3.6026 - val_acc: 0.4269\n","Epoch 28/50\n","1036/1036 [==============================] - 1s 747us/step - loss: 3.5749 - acc: 0.4112 - val_loss: 3.5378 - val_acc: 0.4269\n","Epoch 29/50\n","1036/1036 [==============================] - 1s 756us/step - loss: 3.5113 - acc: 0.4112 - val_loss: 3.4744 - val_acc: 0.4269\n","Epoch 30/50\n","1036/1036 [==============================] - 1s 767us/step - loss: 3.4481 - acc: 0.4112 - val_loss: 3.4129 - val_acc: 0.4269\n","Epoch 31/50\n","1036/1036 [==============================] - 1s 752us/step - loss: 3.3877 - acc: 0.4112 - val_loss: 3.3532 - val_acc: 0.4269\n","Epoch 32/50\n","1036/1036 [==============================] - 1s 762us/step - loss: 3.3286 - acc: 0.4112 - val_loss: 3.2945 - val_acc: 0.4269\n","Epoch 33/50\n","1036/1036 [==============================] - 1s 767us/step - loss: 3.2702 - acc: 0.4112 - val_loss: 3.2376 - val_acc: 0.4269\n","Epoch 34/50\n","1036/1036 [==============================] - 1s 749us/step - loss: 3.2143 - acc: 0.4112 - val_loss: 3.1823 - val_acc: 0.4269\n","Epoch 35/50\n","1036/1036 [==============================] - 1s 777us/step - loss: 3.1598 - acc: 0.4112 - val_loss: 3.1284 - val_acc: 0.4269\n","Epoch 36/50\n","1036/1036 [==============================] - 1s 764us/step - loss: 3.1069 - acc: 0.4112 - val_loss: 3.0754 - val_acc: 0.4269\n","Epoch 37/50\n","1036/1036 [==============================] - 1s 742us/step - loss: 3.0545 - acc: 0.4112 - val_loss: 3.0243 - val_acc: 0.4269\n","Epoch 38/50\n","1036/1036 [==============================] - 1s 761us/step - loss: 3.0044 - acc: 0.4112 - val_loss: 2.9743 - val_acc: 0.4269\n","Epoch 39/50\n","1036/1036 [==============================] - 1s 749us/step - loss: 2.9547 - acc: 0.4112 - val_loss: 2.9254 - val_acc: 0.4269\n","Epoch 40/50\n","1036/1036 [==============================] - 1s 741us/step - loss: 2.9071 - acc: 0.4112 - val_loss: 2.8780 - val_acc: 0.4269\n","Epoch 41/50\n","1036/1036 [==============================] - 1s 755us/step - loss: 2.8600 - acc: 0.4112 - val_loss: 2.8319 - val_acc: 0.4269\n","Epoch 42/50\n","1036/1036 [==============================] - 1s 776us/step - loss: 2.8137 - acc: 0.4112 - val_loss: 2.7869 - val_acc: 0.4269\n","Epoch 43/50\n","1036/1036 [==============================] - 1s 758us/step - loss: 2.7695 - acc: 0.4112 - val_loss: 2.7430 - val_acc: 0.4269\n","Epoch 44/50\n","1036/1036 [==============================] - 1s 766us/step - loss: 2.7256 - acc: 0.4112 - val_loss: 2.7001 - val_acc: 0.4269\n","Epoch 45/50\n","1036/1036 [==============================] - 1s 763us/step - loss: 2.6836 - acc: 0.4112 - val_loss: 2.6585 - val_acc: 0.4269\n","Epoch 46/50\n","1036/1036 [==============================] - 1s 747us/step - loss: 2.6431 - acc: 0.4112 - val_loss: 2.6179 - val_acc: 0.4269\n","Epoch 47/50\n","1036/1036 [==============================] - 1s 763us/step - loss: 2.6030 - acc: 0.4112 - val_loss: 2.5783 - val_acc: 0.4269\n","Epoch 48/50\n","1036/1036 [==============================] - 1s 760us/step - loss: 2.5633 - acc: 0.4112 - val_loss: 2.5400 - val_acc: 0.4269\n","Epoch 49/50\n","1036/1036 [==============================] - 1s 770us/step - loss: 2.5252 - acc: 0.4112 - val_loss: 2.5025 - val_acc: 0.4269\n","Epoch 50/50\n","1036/1036 [==============================] - 1s 765us/step - loss: 2.4884 - acc: 0.4112 - val_loss: 2.4658 - val_acc: 0.4269\n"],"name":"stdout"}]},{"metadata":{"id":"cVcltqKTh6KP","colab_type":"code","outputId":"707beef4-b42c-4749-f082-2ff3790ca7b6","colab":{"base_uri":"https://localhost:8080/","height":5800}},"cell_type":"code","source":["model_tuning()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  \"\"\"\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  import sys\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"],"name":"stderr"},{"output_type":"stream","text":["Found 1036 images belonging to 3 classes.\n","Found 171 images belonging to 3 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=129, epochs=100, validation_steps=171)`\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","129/129 [==============================] - 55s 428ms/step - loss: 1.0847 - acc: 0.4109 - val_loss: 1.0803 - val_acc: 0.4261\n","\n","Epoch 00001: val_acc improved from -inf to 0.42611, saving model to /content/drive/My Drive/Car Insurance/Damage Location/ft_model.h5\n","Epoch 2/100\n","129/129 [==============================] - 53s 412ms/step - loss: 1.0829 - acc: 0.4157 - val_loss: 1.0819 - val_acc: 0.4232\n","\n","Epoch 00002: val_acc did not improve from 0.42611\n","Epoch 3/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0861 - acc: 0.4080 - val_loss: 1.0786 - val_acc: 0.4337\n","\n","Epoch 00003: val_acc improved from 0.42611 to 0.43373, saving model to /content/drive/My Drive/Car Insurance/Damage Location/ft_model.h5\n","Epoch 4/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0850 - acc: 0.4109 - val_loss: 1.0807 - val_acc: 0.4255\n","\n","Epoch 00004: val_acc did not improve from 0.43373\n","Epoch 5/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0856 - acc: 0.4089 - val_loss: 1.0821 - val_acc: 0.4224\n","\n","Epoch 00005: val_acc did not improve from 0.43373\n","Epoch 6/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0832 - acc: 0.4128 - val_loss: 1.0799 - val_acc: 0.4285\n","\n","Epoch 00006: val_acc did not improve from 0.43373\n","Epoch 7/100\n","129/129 [==============================] - 52s 403ms/step - loss: 1.0821 - acc: 0.4196 - val_loss: 1.0801 - val_acc: 0.4270\n","\n","Epoch 00007: val_acc did not improve from 0.43373\n","Epoch 8/100\n","129/129 [==============================] - 51s 396ms/step - loss: 1.0875 - acc: 0.4050 - val_loss: 1.0793 - val_acc: 0.4307\n","\n","Epoch 00008: val_acc did not improve from 0.43373\n","Epoch 9/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0857 - acc: 0.4080 - val_loss: 1.0809 - val_acc: 0.4246\n","\n","Epoch 00009: val_acc did not improve from 0.43373\n","Epoch 10/100\n","129/129 [==============================] - 52s 405ms/step - loss: 1.0823 - acc: 0.4147 - val_loss: 1.0801 - val_acc: 0.4277\n","\n","Epoch 00010: val_acc did not improve from 0.43373\n","Epoch 11/100\n","129/129 [==============================] - 54s 418ms/step - loss: 1.0854 - acc: 0.4079 - val_loss: 1.0803 - val_acc: 0.4270\n","\n","Epoch 00011: val_acc did not improve from 0.43373\n","Epoch 12/100\n","129/129 [==============================] - 51s 398ms/step - loss: 1.0857 - acc: 0.4089 - val_loss: 1.0803 - val_acc: 0.4277\n","\n","Epoch 00012: val_acc did not improve from 0.43373\n","Epoch 13/100\n","129/129 [==============================] - 51s 396ms/step - loss: 1.0820 - acc: 0.4196 - val_loss: 1.0811 - val_acc: 0.4247\n","\n","Epoch 00013: val_acc did not improve from 0.43373\n","Epoch 14/100\n","129/129 [==============================] - 51s 395ms/step - loss: 1.0849 - acc: 0.4099 - val_loss: 1.0802 - val_acc: 0.4269\n","\n","Epoch 00014: val_acc did not improve from 0.43373\n","Epoch 15/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0825 - acc: 0.4157 - val_loss: 1.0801 - val_acc: 0.4277\n","\n","Epoch 00015: val_acc did not improve from 0.43373\n","Epoch 16/100\n","129/129 [==============================] - 53s 414ms/step - loss: 1.0870 - acc: 0.4050 - val_loss: 1.0802 - val_acc: 0.4270\n","\n","Epoch 00016: val_acc did not improve from 0.43373\n","Epoch 17/100\n","129/129 [==============================] - 51s 398ms/step - loss: 1.0861 - acc: 0.4041 - val_loss: 1.0800 - val_acc: 0.4292\n","\n","Epoch 00017: val_acc did not improve from 0.43373\n","Epoch 18/100\n","129/129 [==============================] - 53s 414ms/step - loss: 1.0860 - acc: 0.4099 - val_loss: 1.0806 - val_acc: 0.4261\n","\n","Epoch 00018: val_acc did not improve from 0.43373\n","Epoch 19/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0776 - acc: 0.4292 - val_loss: 1.0803 - val_acc: 0.4262\n","\n","Epoch 00019: val_acc did not improve from 0.43373\n","Epoch 20/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0839 - acc: 0.4157 - val_loss: 1.0811 - val_acc: 0.4255\n","\n","Epoch 00020: val_acc did not improve from 0.43373\n","Epoch 21/100\n","129/129 [==============================] - 51s 399ms/step - loss: 1.0840 - acc: 0.4109 - val_loss: 1.0804 - val_acc: 0.4270\n","\n","Epoch 00021: val_acc did not improve from 0.43373\n","Epoch 22/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0897 - acc: 0.3963 - val_loss: 1.0799 - val_acc: 0.4277\n","\n","Epoch 00022: val_acc did not improve from 0.43373\n","Epoch 23/100\n","129/129 [==============================] - 51s 398ms/step - loss: 1.0778 - acc: 0.4312 - val_loss: 1.0814 - val_acc: 0.4231\n","\n","Epoch 00023: val_acc did not improve from 0.43373\n","Epoch 24/100\n","129/129 [==============================] - 53s 409ms/step - loss: 1.0867 - acc: 0.4031 - val_loss: 1.0795 - val_acc: 0.4300\n","\n","Epoch 00024: val_acc did not improve from 0.43373\n","Epoch 25/100\n","129/129 [==============================] - 52s 399ms/step - loss: 1.0906 - acc: 0.3963 - val_loss: 1.0801 - val_acc: 0.4277\n","\n","Epoch 00025: val_acc did not improve from 0.43373\n","Epoch 26/100\n","129/129 [==============================] - 52s 402ms/step - loss: 1.0838 - acc: 0.4186 - val_loss: 1.0806 - val_acc: 0.4270\n","\n","Epoch 00026: val_acc did not improve from 0.43373\n","Epoch 27/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0819 - acc: 0.4167 - val_loss: 1.0807 - val_acc: 0.4269\n","\n","Epoch 00027: val_acc did not improve from 0.43373\n","Epoch 28/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0854 - acc: 0.4070 - val_loss: 1.0797 - val_acc: 0.4285\n","\n","Epoch 00028: val_acc did not improve from 0.43373\n","Epoch 29/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0840 - acc: 0.4138 - val_loss: 1.0818 - val_acc: 0.4239\n","\n","Epoch 00029: val_acc did not improve from 0.43373\n","Epoch 30/100\n","129/129 [==============================] - 51s 394ms/step - loss: 1.0851 - acc: 0.4147 - val_loss: 1.0800 - val_acc: 0.4277\n","\n","Epoch 00030: val_acc did not improve from 0.43373\n","Epoch 31/100\n","129/129 [==============================] - 51s 399ms/step - loss: 1.0834 - acc: 0.4089 - val_loss: 1.0798 - val_acc: 0.4276\n","\n","Epoch 00031: val_acc did not improve from 0.43373\n","Epoch 32/100\n","129/129 [==============================] - 51s 398ms/step - loss: 1.0832 - acc: 0.4176 - val_loss: 1.0807 - val_acc: 0.4262\n","\n","Epoch 00032: val_acc did not improve from 0.43373\n","Epoch 33/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0851 - acc: 0.4089 - val_loss: 1.0798 - val_acc: 0.4277\n","\n","Epoch 00033: val_acc did not improve from 0.43373\n","Epoch 34/100\n","129/129 [==============================] - 52s 404ms/step - loss: 1.0907 - acc: 0.3934 - val_loss: 1.0798 - val_acc: 0.4292\n","\n","Epoch 00034: val_acc did not improve from 0.43373\n","Epoch 35/100\n","129/129 [==============================] - 51s 397ms/step - loss: 1.0815 - acc: 0.4196 - val_loss: 1.0818 - val_acc: 0.4232\n","\n","Epoch 00035: val_acc did not improve from 0.43373\n","Epoch 36/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0814 - acc: 0.4205 - val_loss: 1.0804 - val_acc: 0.4269\n","\n","Epoch 00036: val_acc did not improve from 0.43373\n","Epoch 37/100\n","129/129 [==============================] - 54s 418ms/step - loss: 1.0839 - acc: 0.4128 - val_loss: 1.0798 - val_acc: 0.4285\n","\n","Epoch 00037: val_acc did not improve from 0.43373\n","Epoch 38/100\n","129/129 [==============================] - 53s 412ms/step - loss: 1.0922 - acc: 0.3866 - val_loss: 1.0814 - val_acc: 0.4262\n","\n","Epoch 00038: val_acc did not improve from 0.43373\n","Epoch 39/100\n","129/129 [==============================] - 52s 406ms/step - loss: 1.0776 - acc: 0.4341 - val_loss: 1.0804 - val_acc: 0.4262\n","\n","Epoch 00039: val_acc did not improve from 0.43373\n","Epoch 40/100\n","129/129 [==============================] - 53s 408ms/step - loss: 1.0848 - acc: 0.4109 - val_loss: 1.0797 - val_acc: 0.4284\n","\n","Epoch 00040: val_acc did not improve from 0.43373\n","Epoch 41/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0826 - acc: 0.4186 - val_loss: 1.0792 - val_acc: 0.4307\n","\n","Epoch 00041: val_acc did not improve from 0.43373\n","Epoch 42/100\n","129/129 [==============================] - 54s 418ms/step - loss: 1.0848 - acc: 0.4099 - val_loss: 1.0822 - val_acc: 0.4202\n","\n","Epoch 00042: val_acc did not improve from 0.43373\n","Epoch 43/100\n","129/129 [==============================] - 54s 419ms/step - loss: 1.0847 - acc: 0.4080 - val_loss: 1.0806 - val_acc: 0.4262\n","\n","Epoch 00043: val_acc did not improve from 0.43373\n","Epoch 44/100\n","129/129 [==============================] - 54s 417ms/step - loss: 1.0863 - acc: 0.4089 - val_loss: 1.0793 - val_acc: 0.4300\n","\n","Epoch 00044: val_acc did not improve from 0.43373\n","Epoch 45/100\n","129/129 [==============================] - 52s 402ms/step - loss: 1.0820 - acc: 0.4176 - val_loss: 1.0807 - val_acc: 0.4254\n","\n","Epoch 00045: val_acc did not improve from 0.43373\n","Epoch 46/100\n","129/129 [==============================] - 53s 412ms/step - loss: 1.0869 - acc: 0.4109 - val_loss: 1.0783 - val_acc: 0.4330\n","\n","Epoch 00046: val_acc did not improve from 0.43373\n","Epoch 47/100\n","129/129 [==============================] - 53s 410ms/step - loss: 1.0883 - acc: 0.3963 - val_loss: 1.0820 - val_acc: 0.4217\n","\n","Epoch 00047: val_acc did not improve from 0.43373\n","Epoch 48/100\n","129/129 [==============================] - 52s 401ms/step - loss: 1.0828 - acc: 0.4244 - val_loss: 1.0798 - val_acc: 0.4285\n","\n","Epoch 00048: val_acc did not improve from 0.43373\n","Epoch 49/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0830 - acc: 0.4118 - val_loss: 1.0801 - val_acc: 0.4284\n","\n","Epoch 00049: val_acc did not improve from 0.43373\n","Epoch 50/100\n","129/129 [==============================] - 54s 422ms/step - loss: 1.0876 - acc: 0.4060 - val_loss: 1.0806 - val_acc: 0.4262\n","\n","Epoch 00050: val_acc did not improve from 0.43373\n","Epoch 51/100\n","129/129 [==============================] - 56s 431ms/step - loss: 1.0853 - acc: 0.4060 - val_loss: 1.0809 - val_acc: 0.4255\n","\n","Epoch 00051: val_acc did not improve from 0.43373\n","Epoch 52/100\n","129/129 [==============================] - 56s 438ms/step - loss: 1.0816 - acc: 0.4186 - val_loss: 1.0807 - val_acc: 0.4255\n","\n","Epoch 00052: val_acc did not improve from 0.43373\n","Epoch 53/100\n","129/129 [==============================] - 56s 431ms/step - loss: 1.0866 - acc: 0.4021 - val_loss: 1.0800 - val_acc: 0.4276\n","\n","Epoch 00053: val_acc did not improve from 0.43373\n","Epoch 54/100\n","129/129 [==============================] - 54s 418ms/step - loss: 1.0803 - acc: 0.4254 - val_loss: 1.0793 - val_acc: 0.4292\n","\n","Epoch 00054: val_acc did not improve from 0.43373\n","Epoch 55/100\n","129/129 [==============================] - 54s 419ms/step - loss: 1.0870 - acc: 0.3983 - val_loss: 1.0799 - val_acc: 0.4292\n","\n","Epoch 00055: val_acc did not improve from 0.43373\n","Epoch 56/100\n","129/129 [==============================] - 52s 405ms/step - loss: 1.0818 - acc: 0.4244 - val_loss: 1.0825 - val_acc: 0.4202\n","\n","Epoch 00056: val_acc did not improve from 0.43373\n","Epoch 57/100\n","129/129 [==============================] - 51s 397ms/step - loss: 1.0850 - acc: 0.4080 - val_loss: 1.0795 - val_acc: 0.4300\n","\n","Epoch 00057: val_acc did not improve from 0.43373\n","Epoch 58/100\n","129/129 [==============================] - 53s 411ms/step - loss: 1.0878 - acc: 0.4021 - val_loss: 1.0806 - val_acc: 0.4254\n","\n","Epoch 00058: val_acc did not improve from 0.43373\n","Epoch 59/100\n","129/129 [==============================] - 54s 419ms/step - loss: 1.0841 - acc: 0.4167 - val_loss: 1.0795 - val_acc: 0.4300\n","\n","Epoch 00059: val_acc did not improve from 0.43373\n","Epoch 60/100\n","129/129 [==============================] - 54s 421ms/step - loss: 1.0871 - acc: 0.4002 - val_loss: 1.0813 - val_acc: 0.4247\n","\n","Epoch 00060: val_acc did not improve from 0.43373\n","Epoch 61/100\n","129/129 [==============================] - 54s 420ms/step - loss: 1.0882 - acc: 0.4021 - val_loss: 1.0800 - val_acc: 0.4277\n","\n","Epoch 00061: val_acc did not improve from 0.43373\n","Epoch 62/100\n","129/129 [==============================] - 54s 416ms/step - loss: 1.0797 - acc: 0.4302 - val_loss: 1.0806 - val_acc: 0.4261\n","\n","Epoch 00062: val_acc did not improve from 0.43373\n","Epoch 63/100\n","129/129 [==============================] - 53s 408ms/step - loss: 1.0831 - acc: 0.4138 - val_loss: 1.0790 - val_acc: 0.4300\n","\n","Epoch 00063: val_acc did not improve from 0.43373\n","Epoch 64/100\n","129/129 [==============================] - 51s 396ms/step - loss: 1.0838 - acc: 0.4118 - val_loss: 1.0810 - val_acc: 0.4262\n","\n","Epoch 00064: val_acc did not improve from 0.43373\n","Epoch 65/100\n","129/129 [==============================] - 51s 393ms/step - loss: 1.0882 - acc: 0.4012 - val_loss: 1.0807 - val_acc: 0.4255\n","\n","Epoch 00065: val_acc did not improve from 0.43373\n","Epoch 66/100\n","129/129 [==============================] - 50s 390ms/step - loss: 1.0838 - acc: 0.4167 - val_loss: 1.0806 - val_acc: 0.4262\n","\n","Epoch 00066: val_acc did not improve from 0.43373\n","Epoch 67/100\n","129/129 [==============================] - 50s 390ms/step - loss: 1.0881 - acc: 0.4002 - val_loss: 1.0812 - val_acc: 0.4239\n","\n","Epoch 00067: val_acc did not improve from 0.43373\n","Epoch 68/100\n","129/129 [==============================] - 51s 394ms/step - loss: 1.0802 - acc: 0.4196 - val_loss: 1.0794 - val_acc: 0.4300\n","\n","Epoch 00068: val_acc did not improve from 0.43373\n","Epoch 69/100\n","129/129 [==============================] - 52s 400ms/step - loss: 1.0825 - acc: 0.4147 - val_loss: 1.0801 - val_acc: 0.4285\n","\n","Epoch 00069: val_acc did not improve from 0.43373\n","Epoch 70/100\n","129/129 [==============================] - 53s 409ms/step - loss: 1.0902 - acc: 0.4002 - val_loss: 1.0806 - val_acc: 0.4255\n","\n","Epoch 00070: val_acc did not improve from 0.43373\n","Epoch 71/100\n","129/129 [==============================] - 51s 392ms/step - loss: 1.0840 - acc: 0.4099 - val_loss: 1.0797 - val_acc: 0.4291\n","\n","Epoch 00071: val_acc did not improve from 0.43373\n","Epoch 72/100\n","129/129 [==============================] - 51s 396ms/step - loss: 1.0825 - acc: 0.4176 - val_loss: 1.0823 - val_acc: 0.4209\n","\n","Epoch 00072: val_acc did not improve from 0.43373\n","Epoch 73/100\n","129/129 [==============================] - 51s 397ms/step - loss: 1.0802 - acc: 0.4244 - val_loss: 1.0798 - val_acc: 0.4292\n","\n","Epoch 00073: val_acc did not improve from 0.43373\n","Epoch 74/100\n","129/129 [==============================] - 51s 397ms/step - loss: 1.0876 - acc: 0.4021 - val_loss: 1.0792 - val_acc: 0.4300\n","\n","Epoch 00074: val_acc did not improve from 0.43373\n","Epoch 75/100\n","129/129 [==============================] - 51s 395ms/step - loss: 1.0846 - acc: 0.4138 - val_loss: 1.0811 - val_acc: 0.4246\n","\n","Epoch 00075: val_acc did not improve from 0.43373\n","Epoch 76/100\n","129/129 [==============================] - 51s 392ms/step - loss: 1.0887 - acc: 0.4002 - val_loss: 1.0801 - val_acc: 0.4270\n","\n","Epoch 00076: val_acc did not improve from 0.43373\n","Epoch 77/100\n","129/129 [==============================] - 51s 394ms/step - loss: 1.0765 - acc: 0.4341 - val_loss: 1.0816 - val_acc: 0.4239\n","\n","Epoch 00077: val_acc did not improve from 0.43373\n","Epoch 78/100\n","129/129 [==============================] - 49s 383ms/step - loss: 1.0874 - acc: 0.4041 - val_loss: 1.0792 - val_acc: 0.4292\n","\n","Epoch 00078: val_acc did not improve from 0.43373\n","Epoch 79/100\n","129/129 [==============================] - 50s 385ms/step - loss: 1.0914 - acc: 0.3895 - val_loss: 1.0809 - val_acc: 0.4262\n","\n","Epoch 00079: val_acc did not improve from 0.43373\n","Epoch 80/100\n","128/129 [============================>.] - ETA: 0s - loss: 1.0811 - acc: 0.4209"],"name":"stdout"}]},{"metadata":{"id":"0-R6pbJ6e-S2","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}